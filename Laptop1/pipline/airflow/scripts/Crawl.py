import random
import time
import pandas as pd
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from collections import defaultdict

# C·∫•u h√¨nh tr√¨nh duy·ªát v·ªõi Undetected ChromeDriver
options = uc.ChromeOptions()
options.add_argument("--incognito")  # Ch·∫°y ·∫©n danh
options.add_argument("--disable-blink-features=AutomationControlled")  # ·∫®n Selenium
options.add_argument("start-maximized")  # M·ªü full m√†n h√¨nh
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36") 
driver = uc.Chrome(options=options)
driver.get("https://www.thegioididong.com/laptop")

# Ch·ªù t·∫£i trang
time.sleep(random.uniform(4, 7))

# L·∫•y danh s√°ch s·∫£n ph·∫©m b·∫±ng c√°ch b·∫•m n√∫t "Xem th√™m"
while True:
    try:
        button = WebDriverWait(driver, 5).until(
            EC.element_to_be_clickable((By.CLASS_NAME, "see-more-btn"))
        )
        ActionChains(driver).move_to_element(button).perform()
        button.click()
        time.sleep(random.uniform(3, 6))  # TƒÉng th·ªùi gian delay ng·∫´u nhi√™n
    except:
        print("Kh√¥ng c√≤n n√∫t 'Xem th√™m', ƒë√£ t·∫£i h·∫øt s·∫£n ph·∫©m.")
        break

data = defaultdict(list)

def scroll_down():
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)

def click_and_get_specs(group_ids, max_items=6):
    specs_data = {}
    for group_id in group_ids:
        try:
            btn = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, f'a[data-group-id="{group_id}"]'))
            )
            ActionChains(driver).move_to_element(btn).perform()
            driver.execute_script("arguments[0].click();", btn)
            WebDriverWait(driver, 2).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".text-specifi.active li"))
            )
            time.sleep(1)
        except:
            continue

        specs = driver.find_elements(By.CSS_SELECTOR, ".text-specifi.active li")
        texts = [spec.text for spec in specs]
        specs_data[group_id] = (texts + ["Kh√¥ng c√≥"] * max_items)[:max_items]

    return specs_data

def get_text_by_class(cls):
    try:
        return driver.find_element(By.CLASS_NAME, cls).text
    except:
        return "Kh√¥ng c√≥"

def get_introduction():
    try:
        tab = WebDriverWait(driver, 3).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, '#tab-spec .tab-link[data-tab="tab-2"]'))
        )
        driver.execute_script("arguments[0].click();", tab)
        time.sleep(1)
        h3s = driver.find_elements(By.CSS_SELECTOR, ".text-detail h3")
        return "; ".join([h3.text.strip() for h3 in h3s if h3.text.strip()])
    except:
        return "Kh√¥ng c√≥"

def fetch_product_data(link):
    if not link.startswith("http"): return
    try:
        driver.get(link)
        time.sleep(random.uniform(3, 5))
        scroll_down()

        name = driver.find_element(By.TAG_NAME, "h1").text
        model = name.split(" ")[1] if len(name.split(" ")) > 1 else "Kh√¥ng c√≥"

        original_price = get_text_by_class("box-price-old")
        price = get_text_by_class("box-price-present")
        sale = get_text_by_class("box-price-percent")

        specs = click_and_get_specs([32, 34, 52, 53, 56, 62], max_items=6)
        intro = get_introduction()

        data["T√™n"].append(name)
        data["Model"].append(model)
        data["Gi√° g·ªëc"].append(original_price)
        data["Gi√° hi·ªán t·∫°i"].append(price)
        data["Khuy·∫øn m√£i"].append(sale)

        data["CPU"].append(specs.get(32, ["Kh√¥ng c√≥"])[0])
        data["S·ªë nh√¢n"].append(specs.get(32, ["Kh√¥ng c√≥"])[1])
        data["S·ªë lu·ªìng"].append(specs.get(32, ["Kh√¥ng c√≥"])[2])
        data["T·ªëc ƒë·ªô CPU"].append(specs.get(32, ["Kh√¥ng c√≥"])[3])
        data["T·ªëc ƒë·ªô t·ªëi ƒëa"].append(specs.get(32, ["Kh√¥ng c√≥"])[4])

        data["RAM"].append(specs.get(34, ["Kh√¥ng c√≥"])[0])
        data["T·ªëc ƒë·ªô RAM"].append(specs.get(34, ["Kh√¥ng c√≥"])[1])
        data["RAM t·ªëi ƒëa"].append(specs.get(34, ["Kh√¥ng c√≥"])[2])
        data["·ªî c·ª©ng"].append(specs.get(34, ["Kh√¥ng c√≥"])[3])

        data["M√†n h√¨nh"].append(specs.get(52, ["Kh√¥ng c√≥"])[0])
        data["ƒê·ªô ph√¢n gi·∫£i"].append(specs.get(52, ["Kh√¥ng c√≥"])[1])
        data["T·∫ßn s·ªë qu√©t"].append(specs.get(52, ["Kh√¥ng c√≥"])[2])
        data["ƒê·ªô ph·ªß m√†u"].append(specs.get(52, ["Kh√¥ng c√≥"])[3])
        data["C√¥ng ngh·ªá m√†n h√¨nh"].append(specs.get(52, ["Kh√¥ng c√≥"])[4])

        data["Card ƒë·ªì h·ªça"].append(specs.get(53, ["Kh√¥ng c√≥"])[0])
        data["C√¥ng ngh·ªá √¢m thanh"].append(specs.get(53, ["Kh√¥ng c√≥"])[1])

        data["C·ªïng k·∫øt n·ªëi"].append(specs.get(56, ["Kh√¥ng c√≥"])[0])
        data["K·∫øt n·ªëi kh√¥ng d√¢y"].append(specs.get(56, ["Kh√¥ng c√≥"])[1])
        data["Webcam"].append(specs.get(56, ["Kh√¥ng c√≥"])[2])
        data["T√≠nh nƒÉng kh√°c"].append(specs.get(56, ["Kh√¥ng c√≥"])[3])
        data["ƒê√®n b√†n ph√≠m"].append(specs.get(56, ["Kh√¥ng c√≥"])[4])

        data["K√≠ch th∆∞·ªõc"].append(specs.get(62, ["Kh√¥ng c√≥"])[0])
        data["Ch·∫•t li·ªáu"].append(specs.get(62, ["Kh√¥ng c√≥"])[1])
        data["H·ªá th·ªëng pin"].append(specs.get(62, ["Kh√¥ng c√≥"])[2])
        data["H·ªá ƒëi·ªÅu h√†nh"].append(specs.get(62, ["Kh√¥ng c√≥"])[3])
        data["Th·ªùi gian ra m·∫Øt"].append(specs.get(62, ["Kh√¥ng c√≥"])[4])

        data["M√¥ t·∫£"].append(intro)
        data["Link"].append(link)

        print(f"‚úî ƒê√£ l·∫•y xong: {name}")
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω {link}: {e}")

# L·∫•y danh s√°ch URL s·∫£n ph·∫©m
try:
    WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, "listproduct")))
    product_urls = list(set([
        a.get_attribute("href")
        for a in driver.find_elements(By.CSS_SELECTOR, ".listproduct a[href]")
        if a.get_attribute("href").startswith("http")
    ]))
except:
    print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch s·∫£n ph·∫©m")
    driver.quit()
    exit()

# Crawl t·ª´ng s·∫£n ph·∫©m
for link in product_urls[:10]:  # test v·ªõi 10 s·∫£n ph·∫©m ƒë·∫ßu
    fetch_product_data(link)

# Chu·∫©n h√≥a chi·ªÅu d√†i
max_len = max(len(v) for v in data.values())
for key in data:
    while len(data[key]) < max_len:
        data[key].append("Kh√¥ng c√≥")

# Xu·∫•t file CSV
df = pd.DataFrame(data)
df.to_csv("merged_laptop_data.csv", index=False, encoding="utf-8-sig")
print("üì¶ ƒê√£ l∆∞u v√†o laptop_full_data.csv")

driver.quit()